apiVersion: apps/v1
kind: Deployment
metadata:
  name: asr-api # Name of the deployment
  namespace: asr-system # Namespace where the deployment will be created
  labels:
    app: asr-api # Label to identify this deployment
spec:
  replicas: 3 # Number of pod replicas to maintain - provides high availability
  selector:
    matchLabels:
      app: asr-api # Selector to identify which pods are managed by this deployment
  strategy:
    type: RollingUpdate # Update strategy - ensures zero downtime during updates
    rollingUpdate:
      maxSurge: 1 # Maximum number of pods that can be created over desired number during update
      maxUnavailable: 0 # No pods can be unavailable during the update - ensures availability
  template:
    metadata:
      labels:
        app: asr-api # Labels applied to the pods created by this deployment
      annotations:
        prometheus.io/scrape: 'true' # Enable Prometheus metrics scraping
        prometheus.io/port: '8000' # Port where metrics are exposed
        prometheus.io/path: /metrics # Path where metrics are available
    spec:
      affinity:
        podAntiAffinity: # Ensures pods are distributed across different nodes
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100   # High weight makes this rule strongly preferred
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - asr-api       # Avoid scheduling pods with this label on the same node
              topologyKey: kubernetes.io/hostname   # Use hostname as the topology key
      containers:
      - name: asr-api
        image: tuandung12092002/asr-fastapi-server:latest   # Container image to use
        imagePullPolicy: Always   # Always pull the latest image version
        command: [/bin/bash, -c]
        args:
        - |
          # Create directory structure if it doesn't exist
          mkdir -p /app/src/models

          # Create __init__.py files to make them proper Python packages
          touch /app/src/__init__.py
          touch /app/src/models/__init__.py

          # Create minimal inference_model.py if it doesn't exist
          if [ ! -f /app/src/models/inference_model.py ]; then
            cat > /app/src/models/inference_model.py << 'EOF'
          import logging

          # Configure logging
          logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
          logger = logging.getLogger("asr-model")

          class ASRInferenceModel:
              def __init__(self, model_id="", device="cpu"):
                  self.model_id = model_id
                  self.device = device
                  logger.info(f"ASR Placeholder Model initialized (model_id={model_id}, device={device})")

              def transcribe(self, audio_path):
                  logger.info(f"Placeholder transcribe method called with {audio_path}")
                  return {"text": "Placeholder ASR response", "duration": 1.0}

          def create_asr_model(model_id="", device="cpu", model_type="pytorch"):
              logger.info(f"Creating placeholder ASR model (model_id={model_id}, type={model_type})")
              return ASRInferenceModel(model_id, device)
          EOF
          fi

          # Start the API server
          cd /app
          python -m uvicorn api.app:app --host 0.0.0.0 --port 8000
        ports:
        - containerPort: 8000     # Port exposed by the container
          name: http     # Name for the port
        resources:   # Resource allocation and limits
          requests:   # Minimum resources needed
            memory: 512Mi
            cpu: 200m
          limits:   # Maximum resources allowed
            memory: 1Gi
            cpu: 500m
        env:   # Environment variables for the container
        - name: PYTHONPATH     # Configure Python module search path
          value: /app
        - name: INFERENCE_DEVICE     # Set device for model inference
          value: cpu
        - name: PORT     # Set API server port
          value: '8000'
        - name: ENABLE_TRACING     # Enable distributed tracing
          value: 'true'
        - name: JAEGER_HOST     # Jaeger collector service for tracing
          value: jaeger-collector.observability.svc.cluster.local
        - name: JAEGER_PORT     # Jaeger collector port
          value: '6831'
        - name: SERVICE_NAME     # Service name for tracing
          value: asr-api
        - name: PROMETHEUS_MULTIPROC_DIR     # Directory for Prometheus metrics in multi-process mode
          value: /tmp/prometheus-metrics
        volumeMounts:   # Mount volumes into the container
        - name: prometheus-metrics     # Volume for storing Prometheus metrics
          mountPath: /tmp/prometheus-metrics
        livenessProbe:   # Checks if the container is running
          httpGet:
            path: /health   # Health check endpoint
            port: 8000
          initialDelaySeconds: 180   # Wait 3 minutes before first probe to allow model loading
          periodSeconds: 10   # Check every 10 seconds
          timeoutSeconds: 5   # Timeout after 5 seconds
          failureThreshold: 6   # Fail after 6 consecutive failures
        readinessProbe:   # Checks if the container is ready to serve requests
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 180   # Wait 3 minutes before first probe to allow model loading
          periodSeconds: 15   # Check every 15 seconds
          timeoutSeconds: 10   # Timeout after 10 seconds
          failureThreshold: 3   # Fail after 3 consecutive failures
        startupProbe:   # Checks if the container has started successfully
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 180   # Wait 3 minutes before first probe to allow model loading
          periodSeconds: 15   # Check every 15 seconds
          timeoutSeconds: 10   # Timeout after 10 seconds
          failureThreshold: 12   # Allow up to 3 minutes (12Ã—15s) for additional startup time
      volumes: # Volumes used by the pod
      - name: prometheus-metrics   # Volume for Prometheus metrics
        emptyDir: {}   # Ephemeral volume that exists for the pod's lifetime
